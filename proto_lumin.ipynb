{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proto_lumin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfS6mUAyptrV"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCFrSfR5p_tO"
      },
      "source": [
        "# Import dependencies\n",
        "\n",
        "We begin by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2QdAAKcqBrs"
      },
      "source": [
        "# System & OS\n",
        "import os\n",
        "import glob\n",
        "# Data Storage\n",
        "from google.colab import drive\n",
        "from zipfile import ZipFile, is_zipfile\n",
        "# Data Analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Data Visualization\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEn3ycl1qPz9"
      },
      "source": [
        "# Mount Storage\n",
        "\n",
        "For simplicity, we keep the data in a Google Drive folder, and simply mount the Google Drive to our Colab instance, as if it were a local file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtNBFwbNqnAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc0cae6-f5a5-4dd7-a95f-3f0f091d67c2"
      },
      "source": [
        "# Mount Google Drive to Colab Instance\n",
        "drive.mount('/content/drive')\n",
        "# Change directory to where the data are stored\n",
        "%cd '/content/drive/MyDrive/Research/Ongoing/Protostellar Luminosity/Data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Research/Ongoing/Protostellar Luminosity/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQiT_cdLCTS2"
      },
      "source": [
        "Unzip the files, if we haven't done so already."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULAGxYruDY-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f20ff8-88f5-4cf2-8e61-6712672b8059"
      },
      "source": [
        "if not os.path.exists('models'):\n",
        "  file_to_extract = 'models.zip'\n",
        "\n",
        "  if os.path.exists(file_to_extract):\n",
        "      if is_zipfile(file_to_extract):\n",
        "          print(f'Valid zip file.\\nExtracting: {file_to_extract}')\n",
        "          # Read in zip file\n",
        "          with ZipFile(file_to_extract,'r') as zip_ref:\n",
        "              # Add progress bar\n",
        "              for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist())):\n",
        "                  # Extract and store in current directory\n",
        "                  zip_ref.extract(member=file)\n",
        "      else:\n",
        "          print('Not valid zip file.')\n",
        "  else:\n",
        "      print(f'Cannot find: {file_to_extract}.')\n",
        "else:\n",
        "  print('Data ready.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPx1957Mq1N0"
      },
      "source": [
        "# Data Analysis\n",
        "\n",
        "Define lists to store every model number, and every inclination value, as well as an empty list to store (model number, class) tuples, for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Clml2o2NcBv"
      },
      "source": [
        "model_num_list = [\"01\", \"02\", \"10\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"30\", \"31\", \"32\", \"33\"]\n",
        "inclinations = [\"05\", \"15\", \"25\", \"35\", \"45\", \"55\", \"65\", \"75\", \"85\"]\n",
        "\n",
        "# Declare a 2D list to store tuples of (model, class) split indeces\n",
        "split_tuples = [[0 for x in range(2)] for y in range(len(model_num_list))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuHwHtxGNm6P"
      },
      "source": [
        "We create a master file to store pertinent model data, and start by writing the header row with relevant column labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKVp5abdNpJK"
      },
      "source": [
        "with open(\"master_file.tbl\", 'w') as master_file:\n",
        "  master_file.write(\"{:<15} {:<20} {:<15} {:<20} {:<25} {:<15}\".format(\"L_int\", \n",
        "                                                                       \"Flux\", \n",
        "                                                                       \"Inclination\", \n",
        "                                                                       \"Wavelength of flux\", \n",
        "                                                                       \"Internal vs Final mass\", \n",
        "                                                                       \"Model Number\"))\n",
        "  master_file.write('\\n')\n",
        "master_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu9u8HYScPTp"
      },
      "source": [
        "Next, loop over every model, reading in the appropriate data, and doing the necessary computations. \n",
        "\n",
        "The end result is a fully populated master file, along with some useful values stored to memory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-en_lWZq8NS"
      },
      "source": [
        "# Loop over every model\n",
        "for i in range(len(model_num_list)):\n",
        "  # The number of timesteps is different for each model; num_times is the result of taking the number of .dat files in each model's RESULTS directory, and dividing by the number of inclinations (to get the number of timesteps)\n",
        "  num_times = int(len(glob.glob1(f'models/run_evolpapiii_newdisk_model{model_num_list[i]}/RESULTS/','*.dat')) / len(inclinations))\n",
        "  # Then, loop from 2 (every model's initial timestep is 2) to num_times + 2 (so it stops at num_times + 1) to get a list with every timestep\n",
        "  timesteps = []\n",
        "  for a in range (2, num_times + 2):\n",
        "    timesteps.append(str(a)) \n",
        "\n",
        "  # Read in the internal luminosity data from the luminosities file\n",
        "  df = pd.read_table(f'models/luminosities_model{model_num_list[i]}.tbl', \n",
        "                     skiprows=1, \n",
        "                     delim_whitespace=True, \n",
        "                     names=['Time (Myr)',\n",
        "                            'Time-t0 (yr)',\n",
        "                            'L_EtoD (Lsun)',\n",
        "                            'L_DM (Lsun)',\n",
        "                            'L_DtoS (Lsun)',\n",
        "                            'L_EtoS (Lsun)',\n",
        "                            'L_DR (Lsun)',\n",
        "                            'L_PHOT (Lsun)',\n",
        "                            'L_INT (Lsun)'])\n",
        "  lint = df['L_INT (Lsun)']\n",
        "  # Read in the mass of the star, disk, and envelope data from the parameters file\n",
        "  df = pd.read_table(f'models/model_parameters_model{model_num_list[i]}.tbl', \n",
        "                     skiprows=1, \n",
        "                     delim_whitespace=True, \n",
        "                     names=['Time (Myr)',\n",
        "                            'Time-t0 (yr)',\n",
        "                            'Mstar (Msun)',\n",
        "                            'Lstar (Lsun)',\n",
        "                            'Rstar (Rsun)',\n",
        "                            'Tstar (K)',\n",
        "                            'Rdisk_in (AU)',\n",
        "                            'Rdisk_out (AU)',\n",
        "                            'Mdisk (Msun)',\n",
        "                            'Renv_in (AU)',\n",
        "                            'Renv_out (AU)',\n",
        "                            'Menv (Msun)',\n",
        "                            'Omega_0 (1/s)',\n",
        "                            'c_s (cm/s)'])\n",
        "  mStar, mDisk, mEnv = df['Mstar (Msun)'], df['Mdisk (Msun)'], df['Menv (Msun)']\n",
        "  # Initialize variables to store class split index, and to keep track of the number of \"missing\" timesteps across all models\n",
        "  split, missing_timesteps = 0, 0\n",
        "\n",
        "  # Open master file to write in pertinent data\n",
        "  with open(\"master_file.tbl\", 'a') as master_file:\n",
        "    # Loop over every spectrum file\n",
        "    for b in range(len(timesteps)):  \n",
        "      for c in range(len(inclinations)):\n",
        "        # Read in the frequency and flux data from the spectrum file\n",
        "        if os.path.isfile(f'models/run_evolpapiii_newdisk_model{model_num_list[i]}/RESULTS/spectrum_{timesteps[b]}_inc{inclinations[c]}.dat') == True: \n",
        "          df = pd.read_table(f'models/run_evolpapiii_newdisk_model{model_num_list[i]}/RESULTS/spectrum_{timesteps[b]}_inc{inclinations[c]}.dat', \n",
        "                             skiprows=2, \n",
        "                             delim_whitespace=True, \n",
        "                             names=['Frequency',\n",
        "                                    'Flux'])\n",
        "          frequency, flux = df['Frequency'], df['Flux']\n",
        "          # Adjust flux data to be consistent with Dunham's previous work\n",
        "          for d in range(len(flux)):\n",
        "            flux[d] = flux[d] * frequency[d] * (1.0 / 140.0)**2\n",
        "          # Loop over every frequency value, to find the wavelength closest to 70 microns\n",
        "          min = 0\n",
        "          for e in range(len(frequency)):\n",
        "            wavelength_test = 2.99792458e14 / frequency[e]\n",
        "            min_test = abs(70 - wavelength_test)\n",
        "            if(min == 0) or (min_test < min):\n",
        "              min = min_test\n",
        "              wavelength = wavelength_test\n",
        "              index = e\n",
        "          # Writing data\n",
        "          master_file.write(\"{:<15} {:<20} {:<15} {:<20} {:<25} {:<15}\".format(lint[int(timesteps[b]) - 1], flux[index], inclinations[c], wavelength, (mStar[b] + mDisk[b]) / (mStar[b] + mDisk[b] + mEnv[b]), model_num_list[i]))\n",
        "          master_file.write('\\n')\n",
        "          # Find the point (index) where the star goes from class 0 to 1\n",
        "          if split == 0:\n",
        "            if (mStar[b] + mDisk[b]) / (mStar[b] + mDisk[b] + mEnv[b]) >= 0.5:\n",
        "              split_tuples[i][1] = b * len(inclinations)\n",
        "        else:\n",
        "          missing_timesteps += 1\n",
        "  master_file.close()\n",
        "\n",
        "  # Find the point (index) where the current model ends\n",
        "  if i == 0:\n",
        "      split_tuples[i][0] = len(timesteps) * len(inclinations) - missing_timesteps\n",
        "  else:\n",
        "      split_tuples[i][0] = split_tuples[i - 1][0] + len(timesteps) * len(inclinations) - missing_timesteps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcd-6TdlN5o9"
      },
      "source": [
        "# Data Visualization\n",
        "\n",
        "To start the visualization process, we first read back in the data from our master file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf_2wTQZc9sP"
      },
      "source": [
        "df = pd.read_table('master_file.tbl', skiprows=1, delim_whitespace=True, names=['L_int', \n",
        "                                                                           'Flux', \n",
        "                                                                           'Inclination', \n",
        "                                                                           'Wavelength of flux', \n",
        "                                                                           'Internal vs Final mass', \n",
        "                                                                           'Model Number'])\n",
        "lint_master, flux_master = df['L_int'], df['Flux']\n",
        "# Initialize master lists to store all class 0 and 1 data\n",
        "lint_master_0, flux_master_0, lint_master_1, flux_master_1, lint_master_log, flux_master_log, lint_master_0_log, flux_master_0_log, lint_master_1_log, flux_master_1_log = [], [], [], [], [], [], [], [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwQez_b6dC4q"
      },
      "source": [
        "Then, loop over each model's data, making 3 plots each (Class 0, Class 1, and Class 0 & 1), all fitted with a linear regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5bfedqAN5yO"
      },
      "source": [
        "# Loop over each tuple in the 2D list split_tuples, such that we consdier only one model at a time\n",
        "for j in range(len(model_num_list)):\n",
        "  # Split out appropriate internal luminosity and flux data\n",
        "  if j == 0:\n",
        "    lint, flux = lint_master[:split_tuples[j][0]], flux_master[:split_tuples[j][0]]\n",
        "  else:\n",
        "    lint, flux = lint_master[split_tuples[j - 1][0]:split_tuples[j][0]], flux_master[split_tuples[j - 1][0]:split_tuples[j][0]]\n",
        "  # Split data into class 0 and 1\n",
        "  lint_0, flux_0, lint_1, flux_1 = lint[:split_tuples[j][1]], flux[:split_tuples[j][1]], lint[split_tuples[j][1]:], flux[split_tuples[j][1]:]\n",
        "  # Take the log (base 10) of each flux and internal luminosity list\n",
        "  lint_log, flux_log, lint_0_log, flux_0_log, lint_1_log, flux_1_log = np.log10(lint), np.log10(flux), np.log10(lint_0), np.log10(flux_0), np.log10(lint_1), np.log10(flux_1)\n",
        "  # Add data to master lists\n",
        "  lint_master_0.extend(lint_0)\n",
        "  flux_master_0.extend(flux_0)\n",
        "  lint_master_1.extend(lint_1)\n",
        "  flux_master_1.extend(flux_1)\n",
        "  lint_master_log.extend(lint_log)\n",
        "  flux_master_log.extend(flux_log)\n",
        "  lint_master_0_log.extend(lint_0_log)\n",
        "  flux_master_0_log.extend(flux_0_log)\n",
        "  lint_master_1_log.extend(lint_1_log)\n",
        "  flux_master_1_log.extend(flux_1_log)\n",
        "\n",
        "  # Make flux vs internal luminosity plots, starting first with Class 0 & 1\n",
        "  plt.scatter(lint, flux)\n",
        "  plt.title(f'Model {model_num_list[j]} Flux vs Internal Luminosity (Class 0 & 1)')\n",
        "  plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "  plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "  plt.xscale('log')\n",
        "  plt.yscale('log')\n",
        "  plt.xlim([10**(-8), 10**2])\n",
        "  plt.ylim([10**(-22), 10**(-14)])\n",
        "\n",
        "  # Plot linear regression, where we only consider internal luminosity values >= 0.1\n",
        "  split_lin_reg = 0\n",
        "  for f in range(len(lint)):\n",
        "    if split_lin_reg == 0:\n",
        "      if lint[f] >= 0.1:   \n",
        "        split_lin_reg = f\n",
        "  # Split the logged data such that internal luminosity values < 0.1 are rejected\n",
        "  lint_log_lin_reg, flux_log_lin_reg = lint_log[split_lin_reg:], flux_log[split_lin_reg:]\n",
        "  # Fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "  m, b = np.polyfit(lint_log_lin_reg, flux_log_lin_reg, 1)\n",
        "  L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "  F = (10 ** b) * (L ** m)\n",
        "  plt.plot(L, F, color='red')\n",
        "\n",
        "  # Save the plot\n",
        "  plt.savefig(f'Figures/model_{model_num_list[j]}_flux_vs_lint_master.eps')\n",
        "  \n",
        "  # Next, for Class 0\n",
        "  plt.scatter(lint_0, flux_0)\n",
        "  plt.title(f'Model {model_num_list[j]} Flux vs Internal Luminosity (Class 0)')\n",
        "  plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "  plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "  plt.xscale('log')\n",
        "  plt.yscale('log')\n",
        "  plt.xlim([10**(-8), 10**2])\n",
        "  plt.ylim([10**(-22), 10**(-14)])\n",
        "\n",
        "  # Plot linear regression, where we only consider internal luminosity values >= 0.1\n",
        "  split_lin_reg = 0\n",
        "  for g in range(len(lint_0)):\n",
        "    if split_lin_reg == 0:\n",
        "      if lint_0[g] >= 0.1:\n",
        "        split_lin_reg = g\n",
        "  # Split the logged data such that internal luminosity values < 0.1 are rejected\n",
        "  lint_0_log_lin_reg, flux_0_log_lin_reg = lint_0_log[split_lin_reg:], flux_0_log[split_lin_reg:]\n",
        "  # Fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "  m, b = np.polyfit(lint_0_log_lin_reg, flux_0_log_lin_reg, 1)\n",
        "  L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "  F = (10 ** b) * (L ** m)\n",
        "  plt.plot(L, F, color='red')\n",
        "\n",
        "  # Save the plot\n",
        "  plt.savefig(f'Figures/model_{model_num_list[j]}_flux_vs_lint_class0.eps')\n",
        "\n",
        "  # Finally, for class 1\n",
        "  plt.scatter(lint_1, flux_1)\n",
        "  plt.title(f'Model {model_num_list[j]} Flux vs Internal Luminosity (Class 1)')\n",
        "  plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "  plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "  plt.xscale('log')\n",
        "  plt.yscale('log')\n",
        "  plt.xlim([10**(-8), 10**2])\n",
        "  plt.ylim([10**(-22), 10**(-14)])\n",
        "\n",
        "  # Plot linear regression, where we note that all internal luminosity values are >= 0.1, meaning we can simply fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "  m, b = np.polyfit(lint_1_log, flux_1_log, 1)\n",
        "  L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "  F = (10 ** b) * (L ** m)\n",
        "  plt.plot(L, F, color='red')\n",
        "\n",
        "  # Save the plot\n",
        "  plt.savefig(f'Figures/model_{model_num_list[j]}_flux_vs_lint_class1.eps')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgYJSLV1dXra"
      },
      "source": [
        "Finally, make 3 master plots containing all the data from every single model (Class 0, Class 1, and Class 0 & 1), again fitting a linear regression to each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJbpRw10gU_Y"
      },
      "source": [
        "# Class 0 & 1\n",
        "plt.scatter(lint_master, flux_master)\n",
        "plt.title('All Models Flux vs Internal Luminosity (Class 0 & 1)')\n",
        "plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlim([10**(-8), 10**2])\n",
        "plt.ylim([10**(-22), 10**(-14)])\n",
        "\n",
        "# Plot linear regression, where we only consider internal luminosity values >= 0.1\n",
        "split_lin_reg = 0\n",
        "for h in range(len(lint_master)):\n",
        "  if split_lin_reg == 0:\n",
        "    if lint_master[h] >= 0.1:   \n",
        "      split_lin_reg = h\n",
        "# Split the logged data such that internal luminosity values < 0.1 are rejected\n",
        "lint_master_log_lin_reg, flux_master_log_lin_reg = lint_master_log[split_lin_reg:], flux_master_log[split_lin_reg:]\n",
        "# Fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "m, b = np.polyfit(lint_master_log_lin_reg, flux_master_log_lin_reg, 1)\n",
        "L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "F = (10 ** b) * (L ** m)\n",
        "plt.plot(L, F, color='red')\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('Figures/flux_vs_lint_master.eps')\n",
        "\n",
        "# Class 0 \n",
        "plt.scatter(lint_master_0, flux_master_0)\n",
        "plt.title('All Models Flux vs Internal Luminosity (Class 0)')\n",
        "plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlim([10**(-8), 10**2])\n",
        "plt.ylim([10**(-22), 10**(-14)])\n",
        "\n",
        "# Plot linear regression, where we only consider internal luminosity values >= 0.1\n",
        "split_lin_reg = 0\n",
        "for i in range(len(lint_master_0)):\n",
        "  if split_lin_reg == 0:\n",
        "    if lint_master_0[i] >= 0.1:\n",
        "      split_lin_reg = g\n",
        "# Split the logged data such that internal luminosity values < 0.1 are rejected\n",
        "lint_master_0_log_lin_reg, flux_master_0_log_lin_reg = lint_master_0_log[split_lin_reg:], flux_master_0_log[split_lin_reg:]\n",
        "# Fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "m, b = np.polyfit(lint_master_0_log_lin_reg, flux_master_0_log_lin_reg, 1)\n",
        "L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "F = (10 ** b) * (L ** m)\n",
        "plt.plot(L, F, color='red')\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('Figures/flux_vs_lint_master_class0.eps')\n",
        "\n",
        "# Class 1\n",
        "plt.scatter(lint_master_1, flux_master_1)\n",
        "plt.title('All Models Flux vs Internal Luminosity (Class 1)')\n",
        "plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlim([10**(-8), 10**2])\n",
        "plt.ylim([10**(-22), 10**(-14)])\n",
        "\n",
        "# Plot linear regression, where we note that all internal luminosity values are >= 0.1, meaning we can simply fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "m, b = np.polyfit(lint_master_1_log, flux_master_1_log, 1)\n",
        "L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "F = (10 ** b) * (L ** m)\n",
        "plt.plot(L, F, color='red')\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('Figures/flux_vs_lint_master_class1.eps')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}