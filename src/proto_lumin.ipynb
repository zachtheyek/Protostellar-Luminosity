{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proto_lumin.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfS6mUAyptrV"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCFrSfR5p_tO"
      },
      "source": [
        "# Import Dependencies\n",
        "\n",
        "We begin by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2QdAAKcqBrs"
      },
      "source": [
        "# System & OS\n",
        "import os\n",
        "import glob\n",
        "# Data Storage\n",
        "from google.colab import drive\n",
        "from zipfile import ZipFile, is_zipfile\n",
        "# Data Analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Data Visualization\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEn3ycl1qPz9"
      },
      "source": [
        "# Mount Storage\n",
        "\n",
        "For simplicity, we keep the data in a Google Drive folder, and simply mount the Google Drive to our Colab instance, as if it were a local file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtNBFwbNqnAG"
      },
      "source": [
        "# Mount Google Drive to Colab Instance\n",
        "drive.mount('/content/drive')\n",
        "# Change directory to where the data are stored\n",
        "%cd '/content/drive/MyDrive/Research/Ongoing/Protostellar Luminosity/Data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQiT_cdLCTS2"
      },
      "source": [
        "Unzip the files, if we haven't done so already."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULAGxYruDY-o"
      },
      "source": [
        "if not os.path.exists('models'):\n",
        "  file_to_extract = 'models.zip'\n",
        "  if os.path.exists(file_to_extract):\n",
        "      if is_zipfile(file_to_extract):\n",
        "          print(f'Valid zip file.\\nExtracting: {file_to_extract}')\n",
        "          # Read in zip file\n",
        "          with ZipFile(file_to_extract,'r') as zip_ref:\n",
        "              # Add progress bar\n",
        "              for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist())):\n",
        "                  # Extract and store in current directory\n",
        "                  zip_ref.extract(member=file)\n",
        "      else:\n",
        "          print('Not valid zip file.')\n",
        "  else:\n",
        "      print(f'Cannot find: {file_to_extract}.')\n",
        "else:\n",
        "  print('Data ready.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPx1957Mq1N0"
      },
      "source": [
        "# Data Analysis\n",
        "\n",
        "Define lists to store every model number, and every inclination value, as well as an empty list to store (model number, class) tuples, for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Clml2o2NcBv"
      },
      "source": [
        "model_num_list = ['01', '02', '10', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '30', '31', '32', '33']\n",
        "inclinations = ['05', '15', '25', '35', '45', '55', '65', '75', '85']\n",
        "\n",
        "# Declare a 2D list to store tuples of (model, class) split indeces\n",
        "split_tuples = [[0 for x in range(2)] for y in range(len(model_num_list))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuHwHtxGNm6P"
      },
      "source": [
        "We create a master file to store pertinent model data, and start by writing the header row with relevant column labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKVp5abdNpJK"
      },
      "source": [
        "with open('master_file.tbl', 'w') as master_file:\n",
        "  master_file.write('{:<15} {:<20} {:<15} {:<20} {:<25} {:<15}'.format('L_int', \n",
        "                                                                       'Flux', \n",
        "                                                                       'Inclination', \n",
        "                                                                       'Wavelength of flux', \n",
        "                                                                       'Internal vs Final mass', \n",
        "                                                                       'Model Number'))\n",
        "  master_file.write('\\n')\n",
        "master_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu9u8HYScPTp"
      },
      "source": [
        "Next, loop over every model, reading in the appropriate data, and doing the necessary computations. \n",
        "\n",
        "The end result is a fully populated master file, along with some useful values stored to memory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-en_lWZq8NS"
      },
      "source": [
        "# Loop over every model\n",
        "for i in tqdm(range(len(model_num_list))):\n",
        "  # The number of timesteps is different for each model; num_times is the result of taking the number of .dat files in each model's RESULTS directory, and dividing by the number of inclinations (to get the number of timesteps)\n",
        "  num_times = int(len(glob.glob1(f'models/run_evolpapiii_newdisk_model{model_num_list[i]}/RESULTS/','*.dat')) / len(inclinations))\n",
        "  # Then, loop from 2 (every model's initial timestep is 2) to num_times + 2 (so it stops at num_times + 1) to get a list with every timestep\n",
        "  timesteps = []\n",
        "  for a in range(2, num_times + 2):\n",
        "    timesteps.append(str(a)) \n",
        "\n",
        "  # Read in the internal luminosity data from the luminosities file\n",
        "  df = pd.read_table(f'models/luminosities_model{model_num_list[i]}.tbl', \n",
        "                     skiprows=1, \n",
        "                     delim_whitespace=True, \n",
        "                     names=['Time (Myr)',\n",
        "                            'Time-t0 (yr)',\n",
        "                            'L_EtoD (Lsun)',\n",
        "                            'L_DM (Lsun)',\n",
        "                            'L_DtoS (Lsun)',\n",
        "                            'L_EtoS (Lsun)',\n",
        "                            'L_DR (Lsun)',\n",
        "                            'L_PHOT (Lsun)',\n",
        "                            'L_INT (Lsun)'])\n",
        "  lint = df['L_INT (Lsun)']\n",
        "  # Read in the mass of the star, disk, and envelope data from the parameters file\n",
        "  df = pd.read_table(f'models/model_parameters_model{model_num_list[i]}.tbl', \n",
        "                     skiprows=1, \n",
        "                     delim_whitespace=True, \n",
        "                     names=['Time (Myr)',\n",
        "                            'Time-t0 (yr)',\n",
        "                            'Mstar (Msun)',\n",
        "                            'Lstar (Lsun)',\n",
        "                            'Rstar (Rsun)',\n",
        "                            'Tstar (K)',\n",
        "                            'Rdisk_in (AU)',\n",
        "                            'Rdisk_out (AU)',\n",
        "                            'Mdisk (Msun)',\n",
        "                            'Renv_in (AU)',\n",
        "                            'Renv_out (AU)',\n",
        "                            'Menv (Msun)',\n",
        "                            'Omega_0 (1/s)',\n",
        "                            'c_s (cm/s)'])\n",
        "  mStar, mDisk, mEnv = df['Mstar (Msun)'], df['Mdisk (Msun)'], df['Menv (Msun)']\n",
        "  # Initialize variables to store class split index, and to keep track of the number of \"missing\" timesteps across all models\n",
        "  split, missing_timesteps = 0, 0\n",
        "\n",
        "  # Open master file to write in pertinent data\n",
        "  with open(\"master_file.tbl\", 'a') as master_file:\n",
        "    # Initialize inner progress bar\n",
        "    with tqdm(total=len(timesteps)*len(inclinations), leave=False) as pbar:\n",
        "      # Loop over every spectrum file\n",
        "      for b in range(len(timesteps)):  \n",
        "        for c in range(len(inclinations)):\n",
        "          # Read in the frequency and flux data from the spectrum file\n",
        "          if os.path.isfile(f'models/run_evolpapiii_newdisk_model{model_num_list[i]}/RESULTS/spectrum_{timesteps[b]}_inc{inclinations[c]}.dat') == True: \n",
        "            df = pd.read_table(f'models/run_evolpapiii_newdisk_model{model_num_list[i]}/RESULTS/spectrum_{timesteps[b]}_inc{inclinations[c]}.dat', \n",
        "                              skiprows=2, \n",
        "                              delim_whitespace=True, \n",
        "                              names=['Frequency',\n",
        "                                      'Flux'])\n",
        "            frequency, flux = df['Frequency'], df['Flux']\n",
        "            # Adjust flux data to be consistent with Dunham's previous work\n",
        "            for d in range(len(flux)):\n",
        "              flux[d] = flux[d] * frequency[d] * (1.0 / 140.0)**2\n",
        "            # Loop over every frequency value, to find the wavelength closest to 70 microns\n",
        "            min = 0\n",
        "            for e in range(len(frequency)):\n",
        "              wavelength_test = 2.99792458e14 / frequency[e]\n",
        "              min_test = abs(70 - wavelength_test)\n",
        "              if(min == 0) or (min_test < min):\n",
        "                min = min_test\n",
        "                wavelength = wavelength_test\n",
        "                index = e\n",
        "            # Writing data\n",
        "            master_file.write('{:<15} {:<20} {:<15} {:<20} {:<25} {:<15}'.format(lint[int(timesteps[b]) - 1], flux[index], inclinations[c], wavelength, (mStar[b] + mDisk[b]) / (mStar[b] + mDisk[b] + mEnv[b]), model_num_list[i]))\n",
        "            master_file.write('\\n')\n",
        "            # Find the point (index) where the star goes from class 0 to 1\n",
        "            if split == 0:\n",
        "              if (mStar[b] + mDisk[b]) / (mStar[b] + mDisk[b] + mEnv[b]) >= 0.5:\n",
        "                split_tuples[i][1] = b * len(inclinations)\n",
        "          else:\n",
        "            missing_timesteps += 1\n",
        "          # Update inner progress bar\n",
        "          pbar.update(1)\n",
        "  master_file.close()\n",
        "\n",
        "  # Find the point (index) where the current model ends\n",
        "  if i == 0:\n",
        "      split_tuples[i][0] = len(timesteps) * len(inclinations) - missing_timesteps\n",
        "  else:\n",
        "      split_tuples[i][0] = split_tuples[i - 1][0] + len(timesteps) * len(inclinations) - missing_timesteps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPdvGULKWNN0"
      },
      "source": [
        "with open('split_tuples.tbl', 'w') as f:\n",
        "  for i in range(len(split_tuples)):\n",
        "    f.write(f'{split_tuples[i][0]} {split_tuples[i][1]}\\n')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcd-6TdlN5o9"
      },
      "source": [
        "# Data Visualization\n",
        "\n",
        "To start the visualization process, we first read back in the data from our master files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf_2wTQZc9sP"
      },
      "source": [
        "df = pd.read_table('master_file.tbl', skiprows=1, delim_whitespace=True, names=['L_int', \n",
        "                                                                                'Flux', \n",
        "                                                                                'Inclination', \n",
        "                                                                                'Wavelength of flux', \n",
        "                                                                                'Internal vs Final mass', \n",
        "                                                                                'Model Number'])\n",
        "lint_master, flux_master = df['L_int'].values.tolist(), df['Flux'].values.tolist()\n",
        "df = pd.read_table('split_tuples.tbl', delim_whitespace=True, names=['Model', \n",
        "                                                                     'Class'])\n",
        "split_tuples = df.values.tolist()\n",
        "# Initialize master lists to store all class 0 and 1 data\n",
        "lint_master_0, flux_master_0, lint_master_1, flux_master_1, lint_master_log, flux_master_log, lint_master_0_log, flux_master_0_log, lint_master_1_log, flux_master_1_log = [], [], [], [], [], [], [], [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwQez_b6dC4q"
      },
      "source": [
        "Then, loop over each model's data, making 3 plots each (Class 0, Class 1, and Class 0 & 1), all fitted with a linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MYzLjpREjHd"
      },
      "source": [
        "---\n",
        "\n",
        "# Omit linear regression for now and just make plots. Could error be in `np.logspace()` instead of `np.linspace()`? Could also be the ranges, i.e. not `[1e-8, 1e+2]`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5bfedqAN5yO"
      },
      "source": [
        "# Loop over each tuple in the 2D list split_tuples, such that we consdier only one model at a time\n",
        "for j in tqdm(range(len(model_num_list))):\n",
        "  # Split out appropriate internal luminosity and flux data\n",
        "  if j == 0:\n",
        "    lint, flux = lint_master[:split_tuples[j][0]], flux_master[:split_tuples[j][0]]\n",
        "  else:\n",
        "    lint, flux = lint_master[split_tuples[j - 1][0]:split_tuples[j][0]], flux_master[split_tuples[j - 1][0]:split_tuples[j][0]]\n",
        "  # Split data into class 0 and 1\n",
        "  lint_0, flux_0, lint_1, flux_1 = lint[:split_tuples[j][1]], flux[:split_tuples[j][1]], lint[split_tuples[j][1]:], flux[split_tuples[j][1]:]\n",
        "  # Take the log (base 10) of each flux and internal luminosity list\n",
        "  lint_log, flux_log, lint_0_log, flux_0_log, lint_1_log, flux_1_log = np.log10(lint), np.log10(flux), np.log10(lint_0), np.log10(flux_0), np.log10(lint_1), np.log10(flux_1)\n",
        "  # Add data to master lists\n",
        "  lint_master_0.extend(lint_0)\n",
        "  flux_master_0.extend(flux_0)\n",
        "  lint_master_1.extend(lint_1)\n",
        "  flux_master_1.extend(flux_1)\n",
        "  lint_master_log.extend(lint_log)\n",
        "  flux_master_log.extend(flux_log)\n",
        "  lint_master_0_log.extend(lint_0_log)\n",
        "  flux_master_0_log.extend(flux_0_log)\n",
        "  lint_master_1_log.extend(lint_1_log)\n",
        "  flux_master_1_log.extend(flux_1_log)\n",
        "\n",
        "  # Make flux vs internal luminosity plots, starting first with Class 0 & 1\n",
        "  plt.scatter(lint, flux, s=20)\n",
        "  plt.title(f'Model {model_num_list[j]} Flux vs Internal Luminosity (Class 0 & 1)')\n",
        "  plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "  plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "  plt.legend([f'Number of datapoints: {len(lint)}'])\n",
        "  plt.xscale('log')\n",
        "  plt.yscale('log')\n",
        "  plt.xlim(1e-19, 1e6)\n",
        "  plt.ylim(1e-15, 1e-5)\n",
        "  # # Plot linear regression, where we only consider internal luminosity values >= 0.1\n",
        "  # split_lin_reg = 0\n",
        "  # for f in range(len(lint)):\n",
        "  #   if split_lin_reg == 0:\n",
        "  #     if lint[f] >= 0.1:   \n",
        "  #       split_lin_reg = f\n",
        "  # # Split the logged data such that internal luminosity values < 0.1 are rejected\n",
        "  # lint_log_lin_reg, flux_log_lin_reg = lint_log[split_lin_reg:], flux_log[split_lin_reg:]\n",
        "  # # Fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "  # m, b = np.polyfit(lint_log_lin_reg, flux_log_lin_reg, 1)\n",
        "  # L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "  # F = (10 ** b) * (L ** m)\n",
        "  # plt.plot(L, F, color='k')\n",
        "  # plt.legend(['Linear regression'])\n",
        "  # # Save & clear plot\n",
        "  plt.savefig(f'Figures/model_{model_num_list[j]}_flux_vs_lint.eps')\n",
        "  plt.clf()\n",
        "  \n",
        "  # Next, for Class 0\n",
        "  plt.scatter(lint_0, flux_0, s=20)\n",
        "  plt.title(f'Model {model_num_list[j]} Flux vs Internal Luminosity (Class 0)')\n",
        "  plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "  plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "  plt.legend([f'Number of datapoints: {len(lint_0)}'])\n",
        "  plt.xscale('log')\n",
        "  plt.yscale('log')\n",
        "  plt.xlim(1e-19, 1e6)\n",
        "  plt.ylim(1e-15, 1e-5)\n",
        "  # # Plot linear regression, where we only consider internal luminosity values >= 0.1\n",
        "  # split_lin_reg = 0\n",
        "  # for g in range(len(lint_0)):\n",
        "  #   if split_lin_reg == 0:\n",
        "  #     if lint_0[g] >= 0.1:\n",
        "  #       split_lin_reg = g\n",
        "  # # Split the logged data such that internal luminosity values < 0.1 are rejected\n",
        "  # lint_0_log_lin_reg, flux_0_log_lin_reg = lint_0_log[split_lin_reg:], flux_0_log[split_lin_reg:]\n",
        "  # # Fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "  # m, b = np.polyfit(lint_0_log_lin_reg, flux_0_log_lin_reg, 1)\n",
        "  # L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "  # F = (10 ** b) * (L ** m)\n",
        "  # plt.plot(L, F, color='k')\n",
        "  # plt.legend(['Linear regression'])\n",
        "  # # Save & clear plot\n",
        "  plt.savefig(f'Figures/model_{model_num_list[j]}_flux_vs_lint_class0.eps')\n",
        "  plt.clf()\n",
        "\n",
        "  # Finally, for class 1\n",
        "  plt.scatter(lint_1, flux_1, s=20)\n",
        "  plt.title(f'Model {model_num_list[j]} Flux vs Internal Luminosity (Class 1)')\n",
        "  plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "  plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "  plt.legend([f'Number of datapoints: {len(lint_1)}'])\n",
        "  plt.xscale('log')\n",
        "  plt.yscale('log')\n",
        "  plt.xlim(1e-19, 1e6)\n",
        "  plt.ylim(1e-15, 1e-5)\n",
        "  # # Plot linear regression, where we note that all internal luminosity values are >= 0.1, meaning we can simply fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "  # m, b = np.polyfit(lint_1_log, flux_1_log, 1)\n",
        "  # L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "  # F = (10 ** b) * (L ** m)\n",
        "  # plt.plot(L, F, color='k')\n",
        "  # plt.legend(['Linear regression'])\n",
        "  # # Save & clear plot\n",
        "  plt.savefig(f'Figures/model_{model_num_list[j]}_flux_vs_lint_class1.eps')\n",
        "  plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgYJSLV1dXra"
      },
      "source": [
        "Finally, make 3 master plots containing all the data from every single model (Class 0, Class 1, and Class 0 & 1), again fitting a linear regression to each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJbpRw10gU_Y"
      },
      "source": [
        "# Class 0 & 1\n",
        "plt.scatter(lint_master, flux_master, s=20)\n",
        "plt.title('All Models Flux vs Internal Luminosity (Class 0 & 1)')\n",
        "plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "plt.legend([f'Number of datapoints: {len(lint_master)}'])\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlim(1e-19, 1e6)\n",
        "plt.ylim(1e-15, 1e-5)\n",
        "# # Plot linear regression, where we only consider internal luminosity values >= 0.1\n",
        "# split_lin_reg = 0\n",
        "# for h in range(len(lint_master)):\n",
        "#   if split_lin_reg == 0:\n",
        "#     if lint_master[h] >= 0.1:   \n",
        "#       split_lin_reg = h\n",
        "# # Split the logged data such that internal luminosity values < 0.1 are rejected\n",
        "# lint_master_log_lin_reg, flux_master_log_lin_reg = lint_master_log[split_lin_reg:], flux_master_log[split_lin_reg:]\n",
        "# # Fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "# m, b = np.polyfit(lint_master_log_lin_reg, flux_master_log_lin_reg, 1)\n",
        "# L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "# F = (10 ** b) * (L ** m)\n",
        "# plt.plot(L, F, color='k')\n",
        "# plt.legend(['Linear regression'])\n",
        "# # Save & clear plot\n",
        "plt.savefig('Figures/master_flux_vs_lint.eps')\n",
        "plt.clf()\n",
        "\n",
        "# Class 0 \n",
        "plt.scatter(lint_master_0, flux_master_0, s=20)\n",
        "plt.title('All Models Flux vs Internal Luminosity (Class 0)')\n",
        "plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "plt.legend([f'Number of datapoints: {len(lint_master_0)}'])\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlim(1e-19, 1e6)\n",
        "plt.ylim(1e-15, 1e-5)\n",
        "# # Plot linear regression, where we only consider internal luminosity values >= 0.1\n",
        "# split_lin_reg = 0\n",
        "# for i in range(len(lint_master_0)):\n",
        "#   if split_lin_reg == 0:\n",
        "#     if lint_master_0[i] >= 0.1:\n",
        "#       split_lin_reg = i\n",
        "# # Split the logged data such that internal luminosity values < 0.1 are rejected\n",
        "# lint_master_0_log_lin_reg, flux_master_0_log_lin_reg = lint_master_0_log[split_lin_reg:], flux_master_0_log[split_lin_reg:]\n",
        "# # Fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "# m, b = np.polyfit(lint_master_0_log_lin_reg, flux_master_0_log_lin_reg, 1)\n",
        "# L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "# F = (10 ** b) * (L ** m)\n",
        "# plt.plot(L, F, color='k')\n",
        "# plt.legend(['Linear regression'])\n",
        "# # Save & clear plot\n",
        "plt.savefig('Figures/master_flux_vs_lint_class0.eps')\n",
        "plt.clf()\n",
        "\n",
        "# Class 1\n",
        "plt.scatter(lint_master_1, flux_master_1, s=20)\n",
        "plt.title('All Models Flux vs Internal Luminosity (Class 1)')\n",
        "plt.xlabel('Internal Luminosity (L$_{sun}$)')\n",
        "plt.ylabel('Flux (erg cm$^{-2}$ s$^{-1}$)')\n",
        "plt.legend([f'Number of datapoints: {len(lint_master_1)}'])\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlim(1e-19, 1e6)\n",
        "plt.ylim(1e-15, 1e-5)\n",
        "# # Plot linear regression, where we note that all internal luminosity values are >= 0.1, meaning we can simply fit the linear regression to the logged data, yielding a slope and intercept (keeping in mind to plot against linear data)\n",
        "# m, b = np.polyfit(lint_master_1_log, flux_master_1_log, 1)\n",
        "# L = np.logspace(10 ** -8, 10 ** 2, 846)\n",
        "# F = (10 ** b) * (L ** m)\n",
        "# plt.plot(L, F, color='k')\n",
        "# plt.legend(['Linear regression'])\n",
        "# # Save & clear plot\n",
        "plt.savefig('Figures/master_flux_vs_lint_class1.eps')\n",
        "plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}